defaults:
  - TurtlebotPPO
  - _self_

params:
  network:
    mlp:
      units: [256, 256, 128]
      activation: elu
      d2rl: False

    rnn:
      name: lstm
      units: 128  
      layers: 1
      before_mlp: False
      concat_input: True
      layer_norm: False
